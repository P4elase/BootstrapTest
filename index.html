<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=UTF-8">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Aptos;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0cm;
	margin-right:0cm;
	margin-bottom:8.0pt;
	margin-left:0cm;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
.MsoChpDefault
	{font-size:12.0pt;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:115%;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:2.0cm 42.5pt 2.0cm 3.0cm;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>

</head>

<body lang=RU style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal><b>0. Что такое признаки, типы признаков, преобразования</b></p>

<p class=MsoNormal>Признаки (features) — это измеримые характеристики объектов,
описывающие их в численной или категориальной форме. Например, в задаче
предсказания цены квартиры признаки могут включать площадь, этаж, район, год
постройки.</p>

<p class=MsoNormal>Типы признаков:</p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Числовые (количественные)</b>: непрерывные (например,
     рост, вес) и дискретные (количество детей).</li>
 <li class=MsoNormal><b>Категориальные</b>: номинальные (цвет: красный,
     зелёный) и порядковые (уровень образования: среднее, высшее).</li>
 <li class=MsoNormal><b>Бинарные</b>: принимают два значения, например, да/нет.</li>
 <li class=MsoNormal><b>Текстовые и временные</b>: необработанные строки, даты,
     временные метки, требующие преобразования.</li>
</ul>

<p class=MsoNormal>Преобразования признаков включают:</p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Нормализация и стандартизация</b> (для числовых
     признаков).</li>
 <li class=MsoNormal><b>One-hot encoding</b> (для номинальных признаков).</li>
 <li class=MsoNormal><b>Label encoding</b> (для порядковых категорий).</li>
 <li class=MsoNormal><b>Обработка пропусков</b> (заполнение средним, медианой
     или специальным значением).</li>
 <li class=MsoNormal><b>Отбор признаков</b>: исключение нерелевантных или
     дублирующих признаков.</li>
</ul>

<p class=MsoNormal>Корректная работа с признаками повышает точность моделей и
ускоряет обучение.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>1. Постановка задачи машинного обучения, этапы</b></p>

<p class=MsoNormal>Машинное обучение (ML) — это область ИИ, где модели
обучаются на данных, чтобы делать прогнозы. Постановка задачи ML начинается с
понимания предметной области и цели анализа.</p>

<p class=MsoNormal><b>Этапы ML-процесса:</b></p>

<ol style='margin-top:0cm' start=1 type=1>
 <li class=MsoNormal><b>Постановка задачи:</b> классификация, регрессия,
     кластеризация и т. д.</li>
 <li class=MsoNormal><b>Сбор данных:</b> источники — датасеты, сенсоры, API,
     базы данных.</li>
 <li class=MsoNormal><b>Предобработка данных:</b> очистка, заполнение
     пропусков, преобразования признаков.</li>
 <li class=MsoNormal><b>Разделение выборки:</b> train/test split или
     кроссвалидация.</li>
 <li class=MsoNormal><b>Выбор модели:</b> линейная регрессия, дерево решений,
     SVM и др.</li>
 <li class=MsoNormal><b>Обучение модели:</b> настройка параметров по обучающей
     выборке.</li>
 <li class=MsoNormal><b>Оценка качества:</b> метрики (accuracy, MAE, RMSE и
     др.).</li>
 <li class=MsoNormal><b>Настройка гиперпараметров:</b> подбор параметров
     (GridSearch, RandomSearch).</li>
 <li class=MsoNormal><b>Интерпретация модели:</b> важность признаков,
     коэффициенты.</li>
 <li class=MsoNormal><b>Развёртывание модели:</b> интеграция в приложение или
     API.</li>
</ol>

<p class=MsoNormal>Каждый этап важен, и ошибки на ранних шагах ведут к плохому
качеству модели.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>2. k-ближайших соседей (kNN)</b></p>

<p class=MsoNormal>kNN — это один из простейших алгоритмов машинного обучения.
Он относится к ленивому обучению, т.е. модель не обучается заранее.</p>

<p class=MsoNormal><b>Суть метода:</b> При предсказании для нового объекта,
алгоритм ищет k ближайших объектов из обучающей выборки и принимает решение по
их меткам (в классификации — голосование, в регрессии — среднее).</p>

<p class=MsoNormal><b>Компоненты:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Метрика расстояния</b>: Евклидово, Манхэттенское и др.</li>
 <li class=MsoNormal><b>Число соседей (k)</b>: гиперпараметр, влияет на
     точность и обобщающую способность.</li>
 <li class=MsoNormal><b>Веса соседей</b>: иногда ближние соседи получают
     больший вес.</li>
</ul>

<p class=MsoNormal><b>Плюсы:</b> простота, отсутствие необходимости в обучении,
хорошо работает при небольшом количестве признаков. <b>Минусы:</b>
чувствительность к масштабу данных, высокая вычислительная сложность при
больших объемах.</p>

<p class=MsoNormal>Перед использованием kNN важно масштабировать признаки
(например, стандартизация).</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>3. Трейн-тест сплит, кроссвалидация, зачем это нужно</b></p>

<p class=MsoNormal>Разделение выборки необходимо для объективной оценки
качества модели. Если модель тестировать на тех же данных, что использовались
для обучения, можно получить переоценку точности.</p>

<p class=MsoNormal><b>Train-test split</b> — деление данных на обучающую и
тестовую выборки (например, 80%/20%). Модель обучается на train и проверяется
на test.</p>

<p class=MsoNormal><b>Плюсы:</b> быстро и просто. <b>Минусы:</b> результат
зависит от конкретного случайного деления.</p>

<p class=MsoNormal><b>Кроссвалидация (cross-validation)</b> — деление данных на
K частей (фолдов). Модель обучается K раз, каждый раз используя одну часть как
валидационную, остальные — как обучающие. Итоговая оценка — среднее по всем
фолдам.</p>

<p class=MsoNormal><b>Плюсы:</b> более стабильная и объективная оценка модели,
особенно на малых выборках. <b>Минусы:</b> выше вычислительные затраты.</p>

<p class=MsoNormal><b>Зачем нужно:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Проверка переобучения модели.</li>
 <li class=MsoNormal>Подбор гиперпараметров (например, выбор числа соседей в
     kNN).</li>
 <li class=MsoNormal>Сравнение моделей по единым критериям.</li>
</ul>

<p class=MsoNormal>Использование валидации — ключ к созданию обобщающей модели.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>4. Метрики классификации</b></p>

<p class=MsoNormal>Метрики классификации позволяют количественно оценить
качество модели, предсказывающей категории.</p>

<p class=MsoNormal><b>Базовая метрика:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Accuracy (точность по классам)</b>: доля правильно
     предсказанных объектов. Accuracy = (TP + TN) / (TP + TN + FP + FN)</li>
</ul>

<p class=MsoNormal><b>Для несбалансированных классов важны:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Precision (точность)</b>: TP / (TP + FP) — насколько
     предсказания положительного класса корректны.</li>
 <li class=MsoNormal><b>Recall (полнота)</b>: TP / (TP + FN) — насколько хорошо
     модель находит все положительные примеры.</li>
 <li class=MsoNormal><b>F1-score</b>: гармоническое среднее precision и recall.</li>
 <li class=MsoNormal><b>ROC-AUC</b>: площадь под кривой ROC — устойчивость к
     порогу классификации.</li>
 <li class=MsoNormal><b>PR-AUC</b>: площадь под кривой Precision-Recall,
     полезна при сильной дисбалансировке классов.</li>
</ul>

<p class=MsoNormal><b>Выбор метрики зависит от задачи:</b> при диагностике
болезней важна полнота, при фильтрации спама — точность.</p>

<p class=MsoNormal>Метрики классификации — обязательный этап оценки и сравнения
моделей.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>5. Метрики регрессии</b></p>

<p class=MsoNormal>В задачах регрессии модель предсказывает непрерывные
значения. Оценка качества проводится с помощью метрик ошибок между
предсказанными и истинными значениями.</p>

<p class=MsoNormal><b>Основные метрики:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b><span lang=EN-US>MAE (Mean Absolute Error)</span></b><span
     lang=EN-US> — </span>среднее абсолютное отклонение<span lang=EN-US>: MAE =
     mean(|y_pred - y_true|)</span></li>
 <li class=MsoNormal><b><span lang=EN-US>MSE (Mean Squared Error)</span></b><span
     lang=EN-US> — </span>средняя квадратичная ошибка<span lang=EN-US>: MSE =
     mean((y_pred - y_true)^2)</span></li>
 <li class=MsoNormal><b><span lang=EN-US>RMSE (Root Mean Squared Error)</span></b><span
     lang=EN-US> — </span>корень из<span lang=EN-US> MSE: RMSE = sqrt(MSE)</span></li>
 <li class=MsoNormal><b>R^2 (коэффициент детерминации)</b> — доля объясненной
     дисперсии: R2 = 1 - (MSE_model / MSE_baseline)</li>
</ul>

<p class=MsoNormal><b>Интерпретация:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>MAE устойчив к выбросам.</li>
 <li class=MsoNormal>MSE и RMSE чувствительны к большим ошибкам (важно при
     штрафе за крупные промахи).</li>
 <li class=MsoNormal>R^2 показывает, насколько хорошо модель объясняет данные
     (близко к 1 — хорошо).</li>
</ul>

<p class=MsoNormal>Выбор метрики зависит от задачи: в финансовом
прогнозировании — MAE, в инженерных — RMSE.</p>

<p class=MsoNormal><b>6. Линейная регрессия, функция потерь, метрики</b></p>

<p class=MsoNormal>Линейная регрессия — базовый алгоритм регрессии, который
пытается найти линейную зависимость между признаками X и целевой переменной y. </p>

<p class=MsoNormal><b>Цель:</b> подобрать такие коэффициенты, чтобы
минимизировать ошибку между предсказанными и реальными значениями.</p>

<p class=MsoNormal><b>Функция потерь:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Наиболее распространённая — <b>среднеквадратичная ошибка
     (MSE)</b>: </li>
</ul>

<p class=MsoNormal><b>Обучение модели</b> — это минимизация функции потерь по
параметрам . Обычно используется метод градиентного спуска или аналитическое
решение (метод наименьших квадратов).</p>

<p class=MsoNormal><b>Метрики оценки:</b> MAE, MSE, RMSE, R^2. Они описаны в
предыдущем вопросе. Также оценивается значение коэффициентов (весов признаков),
знак и масштаб которых можно интерпретировать.</p>

<p class=MsoNormal><b>Плюсы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Простота реализации и интерпретации.</li>
 <li class=MsoNormal>Быстрое обучение.</li>
</ul>

<p class=MsoNormal><b>Минусы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Плохо работает при нелинейных зависимостях.</li>
 <li class=MsoNormal>Чувствительна к выбросам.</li>
</ul>

<p class=MsoNormal>Используется как базовая модель, а также в качестве
объяснимого инструмента анализа.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>8. Корреляция признаков, переобучение линейной модели</b></p>

<p class=MsoNormal><b>Корреляция признаков</b> — наличие линейной (или другой)
зависимости между двумя признаками. Высокая корреляция может приводить к
мультиколлинеарности, особенно критичной для линейных моделей.</p>

<p class=MsoNormal><b>Проблемы корреляции:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Параметры модели становятся нестабильными.</li>
 <li class=MsoNormal>Трудности с интерпретацией весов.</li>
 <li class=MsoNormal>Увеличивается риск переобучения.</li>
</ul>

<p class=MsoNormal><b>Решения:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Удаление одного из сильно коррелирующих признаков.</li>
 <li class=MsoNormal>Использование регуляризации (например, L2-регуляризация).</li>
</ul>

<p class=MsoNormal><b>Переобучение (overfitting)</b> — модель слишком точно
подстраивается под обучающую выборку и теряет обобщающую способность. Признаки
переобучения:</p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Высокая точность на train, низкая на test.</li>
</ul>

<p class=MsoNormal><b>Причины переобучения в линейных моделях:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Слишком много признаков.</li>
 <li class=MsoNormal>Шум в данных.</li>
 <li class=MsoNormal>Коррелированные и нерелевантные признаки.</li>
</ul>

<p class=MsoNormal><b>Борьба с переобучением:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Удаление лишних признаков.</li>
 <li class=MsoNormal>Регуляризация (L1, L2).</li>
 <li class=MsoNormal>Увеличение объема обучающей выборки.</li>
 <li class=MsoNormal>Кроссвалидация для выбора модели и гиперпараметров.</li>
</ul>

<p class=MsoNormal>Понимание корреляции и контроль переобучения — основа
качественного анализа и построения устойчивых моделей.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>10. Линейная классификация, вероятности, функции потерь,
метрики</b></p>

<p class=MsoNormal>Линейная классификация — это использование линейных моделей
для разделения объектов по классам. Примеры: логистическая регрессия, линейный
SVM.</p>

<p class=MsoNormal><b>Модель:</b> <br>
— вероятность принадлежности к положительному классу (в логистической
регрессии).</p>

<p class=MsoNormal><b>Функция потерь:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Log-loss (бинарная кросс-энтропия):</b> </li>
</ul>

<p class=MsoNormal><b>Порог вероятности:</b> по умолчанию 0.5, но может быть
смещен в зависимости от задачи.</p>

<p class=MsoNormal><b>Метрики:</b> те же, что в классификации: accuracy,
precision, recall, F1, ROC-AUC.</p>

<p class=MsoNormal><b>Плюсы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Простота и интерпретируемость.</li>
 <li class=MsoNormal>Быстро обучается.</li>
</ul>

<p class=MsoNormal><b>Минусы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Плохо работает при сложных нелинейных зависимостях.</li>
 <li class=MsoNormal>Не справляется с сильной мультиколлинеарностью без
     регуляризации.</li>
</ul>

<p class=MsoNormal>Линейная классификация — основа для многих задач, особенно
при ограниченных данных и потребности в объяснимости.</p>

<p class=MsoNormal><b>12. Метод опорных векторов (SVM)</b></p>

<p class=MsoNormal>Метод опорных векторов (Support Vector Machine, SVM) —
алгоритм для задач классификации и регрессии, который стремится найти
оптимальную границу между классами с максимальным зазором (margin).</p>

<p class=MsoNormal><b>Принцип работы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>SVM находит гиперплоскость, которая максимально разделяет
     два класса.</li>
 <li class=MsoNormal>Опорные вектора — это те точки, которые находятся ближе
     всего к границе и определяют её положение.</li>
</ul>

<p class=MsoNormal><b>Формализация:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Задача оптимизации: максимизировать расстояние до
     ближайших точек классов, при этом минимизируя ошибки (в soft-margin
     варианте).</li>
 <li class=MsoNormal>Возможна регуляризация через параметр C — штраф за
     ошибочную классификацию.</li>
</ul>

<p class=MsoNormal><b>Ядра (kernel trick):</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>При наличии нелинейных границ используется трюк ядра:
     преобразование признаков в более высокое измерение.</li>
 <li class=MsoNormal>Популярные ядра: полиномиальное, радиально-базисное (RBF),
     сигмоидное.</li>
</ul>

<p class=MsoNormal><b>Плюсы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Работает в высоких размерностях.</li>
 <li class=MsoNormal>Эффективен при небольшом числе наблюдений.</li>
 <li class=MsoNormal>Хорошо решает задачи с чёткой границей классов.</li>
</ul>

<p class=MsoNormal><b>Минусы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Требует нормализации признаков.</li>
 <li class=MsoNormal>Плохо масштабируется на большие выборки.</li>
 <li class=MsoNormal>Трудно интерпретируем.</li>
</ul>

<p class=MsoNormal>SVM — мощный метод для сложных задач, особенно когда данные
хорошо разделимы в преобразованном пространстве.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>14. Нормализация данных для линейной модели, стратегии
масштабирования</b></p>

<p class=MsoNormal>Масштабирование признаков — обязательный шаг перед обучением
линейных моделей, особенно чувствительных к масштабу (например, логистическая
регрессия, SVM, kNN).</p>

<p class=MsoNormal><b>Зачем нужно:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Ускоряет сходимость градиентного спуска.</li>
 <li class=MsoNormal>Делает коэффициенты интерпретируемыми.</li>
 <li class=MsoNormal>Повышает точность модели.</li>
</ul>

<p class=MsoNormal><b>Основные стратегии масштабирования:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Стандартизация (StandardScaler):</b> вычитание среднего
     и деление на стандартное отклонение. Результат — признаки с нулевым
     средним и единичной дисперсией.</li>
 <li class=MsoNormal><b>Масштабирование в диапазон [0, 1] (MinMaxScaler):</b>
     вычитание минимального значения и деление на разницу max-min.</li>
 <li class=MsoNormal><b>Масштабирование по максимальному модулю (MaxAbsScaler):</b>
     деление на максимальное абсолютное значение.</li>
 <li class=MsoNormal><b>Робастное масштабирование (RobustScaler):</b> устойчиво
     к выбросам, использует медиану и межквартильный размах.</li>
</ul>

<p class=MsoNormal>Выбор метода зависит от данных. При наличии выбросов лучше
использовать робастные методы. Стандартизация — самый универсальный подход.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>16. Деревья решений</b></p>

<p class=MsoNormal>Дерево решений — алгоритм, основанный на последовательном
разбиении признаков на интервалы, формируя древовидную структуру для
предсказания класса или значения.</p>

<p class=MsoNormal><b>Принцип:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>В каждом узле выбирается признак и порог, по которому
     данные делятся так, чтобы уменьшалась неопределенность.</li>
</ul>

<p class=MsoNormal><b>Критерии разбиения:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>Классификация:</b> индекс Джини, энтропия.</li>
 <li class=MsoNormal><b>Регрессия:</b> среднеквадратичная ошибка.</li>
</ul>

<p class=MsoNormal><b>Плюсы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Интерпретируемость.</li>
 <li class=MsoNormal>Возможность работать с категориальными и числовыми
     признаками.</li>
 <li class=MsoNormal>Не требует масштабирования.</li>
</ul>

<p class=MsoNormal><b>Минусы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Склонны к переобучению.</li>
 <li class=MsoNormal>Малые изменения в данных могут сильно изменить дерево.</li>
</ul>

<p class=MsoNormal><b>Методы борьбы с переобучением:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Ограничение глубины дерева.</li>
 <li class=MsoNormal>Ограничение минимального количества объектов в листе.</li>
 <li class=MsoNormal>Пост-обрезка дерева (pruning).</li>
</ul>

<p class=MsoNormal>Деревья — основа многих ансамблевых методов, например,
случайного леса и градиентного бустинга.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>18. Бутстрэп и метод случайных подпространств</b></p>

<p class=MsoNormal><b>Бутстрэп (bootstrap)</b> — метод случайной выборки с
возвращением, используемый для оценки устойчивости модели или построения
ансамблей.</p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Пример: для построения дерева в случайном лесе
     используется бутстрэп-выборка из исходных данных.</li>
 <li class=MsoNormal>Это позволяет моделям обучаться на разных подмножествах и
     снижает переобучение.</li>
</ul>

<p class=MsoNormal><b>Метод случайных подпространств:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>При построении каждой модели в ансамбле (например, дерева)
     случайным образом выбирается подмножество признаков.</li>
 <li class=MsoNormal>Обеспечивает разнообразие среди моделей.</li>
</ul>

<p class=MsoNormal><b>Оба метода важны для:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Повышения обобщающей способности ансамблей.</li>
 <li class=MsoNormal>Борьбы с переобучением.</li>
</ul>

<p class=MsoNormal>Их совместное использование — ключевой принцип случайного
леса и некоторых реализаций градиентного бустинга.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>19. Случайный лес</b></p>

<p class=MsoNormal>Случайный лес (Random Forest) — ансамблевый метод,
основанный на построении множества деревьев решений с использованием бутстрэпа
и случайных подпространств признаков.</p>

<p class=MsoNormal><b>Принцип:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Строится N деревьев решений.</li>
 <li class=MsoNormal>Каждый обучается на бутстрэп-выборке.</li>
 <li class=MsoNormal>В каждом узле случайно выбирается подмножество признаков
     для разбиения.</li>
 <li class=MsoNormal>Предсказание: классификация — голосование, регрессия —
     среднее.</li>
</ul>

<p class=MsoNormal><b>Плюсы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Устойчив к переобучению.</li>
 <li class=MsoNormal>Работает с различными типами данных.</li>
 <li class=MsoNormal>Хорошо масштабируется.</li>
</ul>

<p class=MsoNormal><b>Минусы:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal>Менее интерпретируем по сравнению с одиночными деревьями.</li>
 <li class=MsoNormal>Требует больше памяти и вычислений.</li>
</ul>

<p class=MsoNormal>Используется во многих прикладных задачах как точный и
надёжный базовый алгоритм.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>26. Параметры и гиперпараметры моделей</b></p>

<p class=MsoNormal><b>Параметры</b> — значения, обучаемые моделью из данных
(например, веса в линейной регрессии).</p>

<p class=MsoNormal><b>Гиперпараметры</b> — настройки модели, задаваемые до
обучения. Их подбирают с помощью кроссвалидации, поиска по сетке и др.</p>

<p class=MsoNormal><b>Примеры:</b></p>

<ul style='margin-top:0cm' type=disc>
 <li class=MsoNormal><b>kNN:</b> k — число соседей, метрика расстояния.</li>
 <li class=MsoNormal><b>Деревья решений:</b> максимальная глубина, минимальное
     число объектов в листе, критерий разбиения.</li>
 <li class=MsoNormal><b>Линейные модели:</b> коэффициент регуляризации (C,
     alpha), тип регуляризации (L1, L2).</li>
</ul>

<p class=MsoNormal>Подбор гиперпараметров влияет на качество модели.
Неправильный выбор может привести к переобучению или недообучению. Для выбора
используют GridSearchCV, RandomSearch, Optuna и другие методы.</p>

<p class=MsoNormal><span lang=EN-US>&nbsp;</span></p>

</div>

</body>

</html>
